1.
2. The default behavior is RESTRICT, where DROP DATABASE will fail if the database is not empty. 
  To drop the tables in the database as well, use DROP DATABASE ... CASCADE.
  USAGE:
  DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];
3. To check which database is currently being used: SELECT current_database() 
4. Enable delete,update...
  http://www.aboutyun.com/thread-12155-1-1.html
  https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions#HiveTransactions-TableProperties

  If a table is to be used in ACID writes (insert, update, delete) then the table property "transactional=true" must be set on that table, starting with Hive 0.14.0. Note, once a table has been defined as an ACID table via TBLPROPERTIES ("transactional"="true"), it cannot be converted back to a non-ACID table, i.e., changing TBLPROPERTIES ("transactional"="false") is not allowed. 
  Also, hive.txn.manager must be set to org.apache.hadoop.hive.ql.lockmgr.DbTxnManager either in hive-site.xml or in the beginning of the session before any query is run. 
  Without those, inserts will be done in the old style; updates and deletes will be prohibited prior to HIVE-11716.  
  Since HIVE-11716 operations on ACID tables without DbTxnManager are not allowed.  
  However, this does not apply to Hive 0.13.0.

5.调试hive运行时，单独设置日志：
  hive --hiveconf hive.root.logger=DEBUG,console


1. Any column name that is specified within backticks (`) is treated literally. Within a backtick string, use double backticks (``) to represent a backtick character. 
  Backtick quotation also enables the use of reserved keywords for table and column identifiers.
2. To find out if a table is managed or external, look for tableType in the output of DESCRIBE EXTENDED|FORMATTED table_name.
  e.g.
    hive> describe extended fgvdu;
    Detailed Table Information(..., tableType:MANAGED_TABLE)
    hive> describe formatted fgvdu;
    # Detailed Table Information
    Table Type:             MANAGED_TABLE
3. The TBLPROPERTIES clause allows you to tag the table definition with your own metadata key/value pairs.
4. As of Hive 0.13.0, a table can be made immutable by creating it with TBLPROPERTIES ("immutable"="true"). 
  The default is "immutable"="false".
  INSERT INTO behavior into an immutable table is disallowed if any data is already present, although INSERT INTO still works if the immutable table is empty. 
  The behavior of INSERT OVERWRITE is not affected by the "immutable" table property.
  An immutable table is protected against accidental updates due to a script loading data into it being run multiple times by mistake. 
  The first insert into an immutable table succeeds and successive inserts fail, resulting in only one set of data in the table, instead of silently succeeding with multiple copies of the data in the table. 
  e.g.
    hive> create temporary table test_tbl(id int,name string) row format delimited fields terminated by '\t' tblproperties("immutable"="true");
    OK
    Time taken: 0.274 seconds
    hive> insert into table test_tbl values(1,'allen'),(2,'kobe'),(3,'wade');
    OK
    Time taken: 21.24 seconds
    hive> select * from test_tbl;
    OK
    1       allen
    2       kobe
    3       wade
    Time taken: 0.093 seconds, Fetched: 3 row(s)
    hive> insert into table test_tbl values(1,'allen'),(2,'kobe'),(3,'wade');
    FAILED: SemanticException [Error 10256]: Inserting into a non-empty immutable table is not allowed test_tbl
5.TBLPROPERTIES ("auto.purge"="true") or ("auto.purge"="false") in release 1.2.0+ .
    Apply for: Drop Table, Drop Partitions, Truncate Table, and Insert Overwrite.
    e.g.
    DROP TABLE [IF EXISTS] table_name [PURGE];     -- (Note: PURGE available in Hive 0.14.0 and later)
    If PURGE is specified, the table data does not go to the .Trash/Current directory and so cannot be retrieved in the event of a mistaken DROP. 
    The purge option can also be specified with the table property auto.purge (see TBLPROPERTIES above).
6.TBLPROPERTIES ("EXTERNAL"="TRUE") in release 0.6.0+ (HIVE-1329) – Change a managed table to an external table and vice versa for "FALSE".
  As of Hive 2.4.0 (HIVE-16324) the value of the property 'EXTERNAL' is parsed as a boolean (case insensitive true or false) instead of a case sensitive string comparison.
7.WHEN use managed table:
  Use managed tables when Hive should manage the lifecycle of the table, or when generating temporary tables.
8. Use external tables when files are already present or in remote locations, and the files should remain even if the table is dropped.
9. If the structure or partitioning of an external table is changed, an MSCK REPAIR TABLE table_name statement can be used to refresh metadata information.
  Recover Partitions (MSCK REPAIR TABLE)
  Hive stores a list of partitions for each table in its metastore. 
  If, however, new partitions are directly added to HDFS (say by using hadoop fs -put command), the metastore (and hence Hive) will not be aware of these partitions unless the user runs ALTER TABLE table_name ADD PARTITION commands on each of the newly added partitions.
  However, users can run a metastore check command with the repair table option:
  MSCK REPAIR TABLE table_name;which will add metadata about partitions to the Hive metastore for partitions for which such metadata doesn't already exist. 
  In other words, it will add any partitions that exist on HDFS but not in metastore to the metastore. See HIVE-874 for more details. 
  When there is a large number of untracked partitions, there is a provision to run MSCK REPAIR TABLE batch wise to avoid OOME (Out of Memory Error). By giving the configured batch size for the property hive.msck.repair.batch.size it can run in the batches internally. The default value of the property is zero, it means it will execute all the partitions at once.
  e.g.
    hive> create external table test_msck(id int,name string) partitioned by(class string) row format delimited fields terminated by '\t' location '/user/hive/external/test_msck';
    OK
    Time taken: 0.172 seconds
    hive> insert into table test_msck partition(class="top1") values(1,'allen'),(2,'kobe'),(3,'wade');
    OK
    Time taken: 18.411 seconds
    hive> dfs -ls /user/hive/external/test_msck;
    Found 1 items
    drwxr-xr-x   - jiyuan supergroup          0 2017-07-25 16:28 /user/hive/external/test_msck/class=top1
    hive> dfs -cp /user/hive/external/test_msck/class=top1/000000_0 /user/hive/external/test_msck/class=top2/000000_0;
    hive> dfs -ls /user/hive/external/test_msck/;
    Found 2 items
    drwxr-xr-x   - jiyuan supergroup          0 2017-07-25 16:28 /user/hive/external/test_msck/class=top1
    drwxr-xr-x   - jiyuan supergroup          0 2017-07-25 16:31 /user/hive/external/test_msck/class=top2
    hive> select * from test_msck where class = "top1";
    OK
    1       allen   top1
    2       kobe    top1
    3       wade    top1
    Time taken: 0.118 seconds, Fetched: 3 row(s)
    hive> select * from test_msck where class = "top2";
    OK
    Time taken: 0.125 seconds
    hive> msck repair table test_msck;
    OK
    Partitions not in metastore:    test_msck:class=top2
    Repair: Added partition to metastore test_msck:class=top2
    Time taken: 0.188 seconds, Fetched: 2 row(s)
10. storage format comparation: sequenceFile and rcFile:
  参考《hadoop权威指南》474page
  当我们查询表的某一行中确定某列时：
  sequenceFileTBL 会将这一个列值前面所有行所有列的字节都加载到内存中，但是由于“迟反序列化”策略（lazy deserialization）只反序列化确定的哪一个列值。
  rcFileTBL 只会加载这一列中所有的值到内存中。比sequence文件节省内存空间。
  create table tblname1 
    stored as sequencefile;
  create table tblname2 
    row format serde 'org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe' 
    stored as rcfile;
  e.g.
    Table fudan_novel_info exsits.
    hive> create table demo_sequence_storaged stored as sequencefile as select * from fudan_novel_info exsits;
    OK
    hive> create table demo_storage_rcfile row format serde 'org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe' stored as rcfile as select * from fudan_novel_info;
    OK
    hive> select chapter_name from demo_sequence_storaged where chapter_name = '又被退婚&nbsp&nbsp&nbsp在梦里也要解气';
    OK
    又被退婚&nbsp&nbsp&nbsp在梦里也要解气
    又被退婚&nbsp&nbsp&nbsp在梦里也要解气
    Time taken: 0.599 seconds, Fetched: 2 row(s)
    hive> select chapter_name from demo_storage_rcfile where chapter_name = '又被退婚&nbsp&nbsp&nbsp在梦里也要解气';
    OK
    又被退婚&nbsp&nbsp&nbsp在梦里也要解气
    又被退婚&nbsp&nbsp&nbsp在梦里也要解气
    Time taken: 0.129 seconds, Fetched: 2 row(s)
    So,sequence:0.599,rc:0.129.4.6倍。rcFile 查询某一列的值时会快很多并且节省内存空间。
    
11.EXPORT DATA: 
	e.g.
    HDFS(INSERT): 1file
      hive> insert overwrite directory 'hdfs://internal0/user/hive/external/test' select * from fudan_novel_info;
      hive> dfs -ls hdfs://internal0/user/hive/external/test;
      Found 1 items
      -rwxr-xr-x   1 jiyuan supergroup     251794 2017-07-20 16:57 hdfs://internal0/user/hive/external/test/000000_0
    LOCAL（INSERT）: 3files
      hive> insert overwrite local directory '/home/jiyuan/new_project_rjdai/07202017/test' select * from fudan_novel_info;
      hive> !ls /home/jiyuan/new_project_rjdai/07202017/test;
      000000_0
      000001_0
      000002_0
      INFO: generates many files rather than several big files?INSERT OVERWRITE statements to HDFS filesystem directories are the best way to extract large amounts of data from Hive. Hive can write to HDFS directories in parallel from within a map-reduce job.
    Download data:
      hdfs dfs -get hdfs://internal0/user/hive/external/test/000000_0;
      INFO:Download method just download raw data within create storage file format,such as: testfile,sequencefile,rcfile...
    Shell Script:
      hive -e 'select * from db.test;' > /localdir
      
12. 存储格式，两个维度：行格式和文件格式。
行格式  ：指行和一行中的字段如何存储。行格式的存储有SerDe定义。SerDe是，hadoop api提供的接口工具，用来进行序列化（insert ctas）和反序列化(查询)。
				行格式有很多hadoop api借口类型：参考《hadoop权威指南》p473,例如：LazySimpleSerDe,BinarySortableSerDe,ColumnarSerDe,RegexSerDe,HBaseSerDe等。
				Built-in SerDes
					Avro (Hive 0.9.1 and later)
					ORC (Hive 0.11 and later)
					RegEx
					Thrift
					Parquet (Hive 0.13 and later) Referto:https://cwiki.apache.org/confluence/display/Hive/Parquet#Parquet-Introduction
					CSV (Hive 0.14 and later)
					JsonSerDe (Hive 0.12 and later in hcatalog-core)
				custom SerDes
文件格式：指一行中字段容器的格式。基本两种格式：文本文件格式，面向或者列二进制格式。
				分类：常用:textfile(default),SEQUENCEFILE,rcfile,orc(recommend)；不常用：Avro,PARQUET;自定义:INPUTFORMAT and OUTPUTFORMAT
行格式是针对于表数据内容在传输过程的数据格式，对数据；文件格式是针对于表数据将要存储所在的容器的格式，对文件。
文件格式性能对比：
referto:
lib.csdn.net/article/hive/42004
http://www.ccblog.cn/69.htm
textfile 		 存储空间消耗比较大，并且压缩的text 无法分割和合并 查询的效率最低,可以直接存储，加载数据的速度最高
sequencefile 存储空间消耗最大,压缩的文件可以分割和合并 需要通过text文件转化来加载
rcfile 			 存储空间小，查询的效率高 ，需要通过text文件转化来加载，加载的速度最低
orc 				 存储空间最小，查询的最高 ，需要通过text文件转化来加载，加载的速度最低（个人建议使用orc）
13.partition column:
	hive既可以有一个字段在数据中，又可以有一个字段当做分区表，这两个字段是同一个字段，只不过是不同名称：
	If, when creating a partitioned table, you get this error: "FAILED: Error in semantic analysis: Column repeated in partitioning columns," 
	it means you are trying to include the partitioned column in the data of the table itself. 
	You probably really do have the column defined. However, the partition you create makes a pseudocolumn on which you can query, 
	so you must rename your table column to something else (that users should not query on!).
	For example, suppose your original unpartitioned table had three columns: id, date, and name.
	Example:
		id     int,
		date   date,
		name   varchar
	Now you want to partition on date. Your Hive definition could use "dtDontQuery" as a column name so that "date" can be used for partitioning (and querying).
	Example:
		create table table_name (
			id                int,
			dtDontQuery       string,
			name              string
		)
		partitioned by (date string)；
	Now your users will still query on "where date = '...'" but the second column dtDontQuery will hold the original values.
14.External Tables
	The EXTERNAL keyword lets you create a table and provide a LOCATION so that Hive does not use a default location for this table. 
	This comes in handy if you already have data generated. 
	@@When dropping an EXTERNAL table, data in the table is NOT deleted from the file system.

15.CTAS
	Being able to select data from one table to another is one of the most powerful features of Hive.
	1）
	The table created by CTAS is atomic, meaning that the table is not seen by other users until all the query results are populated. 
	So other users will either see the table with the complete results of the query or will not see the table at all.
	e.g.
		hive> create table demo_ctas as select * from fudan_novel_info where lol='hah';
		FAILED: SemanticException [Error 10004]: Line 1:63 Invalid table alias or column reference 'lol': (possible column names are: novel_word_count, novel_reward_url, novel_style, novel_name, novel_code, novel_url, novel_collect_count, novel_review_url, novel_site, chapter_name, novel_author, novel_collect_url, novel_flag, novel_update_date, novel_vote_url, novel_state, novel_view, chapter_url, novel_type)
		hive> show tables;
		OK
		fudan_novel_info
		Time taken: 0.029 seconds, Fetched: 5 row(s)
	Node:select statement failed so all failed.
@However,if select statement return a null res, and the table will created with null.
	e.g.
		hive> create table demo_ctas as select * from fudan_novel_info where novel_name = "齐天大圣";
		maplog
		...
		OK
		Time taken: 22.732 seconds
		hive> show tables;
		OK
		demo_ctas
		fudan_novel_info
		Time taken: 0.029 seconds, Fetched: 6 row(s)
		hive> select * from demo_ctas;
		OK
		Time taken: 0.139 seconds
		2）
		The CREATE part of the CTAS takes the resulting schema from the SELECT part and creates the target table with other table properties such as the SerDe and storage format.
		 In addition, the new target table is created using a specific SerDe and a storage format independent of the source tables in the SELECT statement.
		e.g.
			CREATE TABLE new_key_value_store
			ROW FORMAT SERDE "org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe"
			STORED AS RCFile
				AS
			SELECT (key % 1024) new_key, concat(key, value) key_value_pair
			FROM key_value_store
			SORT BY new_key, key_value_pair;
@@@	3）restrictions
		CTAS has these restrictions:
    The target table cannot be a partitioned table.
    The target table cannot be an external table.
    The target table cannot be a list bucketing table.
16.Bucketed Sorted Tables
	1）创建
		referto:
			https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL+BucketedTables
			https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL
			《hadoop权威指南》p468
@@@Such an organization allows the user to do efficient sampling on the clustered column. 
		Example:
			CREATE TABLE page_view(viewTime INT, userid BIGINT,
					 page_url STRING, referrer_url STRING,
					 ip STRING COMMENT 'IP Address of the User')
			 COMMENT 'This is the page view table'
			 PARTITIONED BY(dt STRING, country STRING)
			 CLUSTERED BY(userid) SORTED BY(viewTime) INTO 32 BUCKETS
			 ROW FORMAT DELIMITED
				 FIELDS TERMINATED BY '\001'
				 COLLECTION ITEMS TERMINATED BY '\002'
				 MAP KEYS TERMINATED BY '\003'
			 STORED AS SEQUENCEFILE;
		In the example above, the page_view table is bucketed (clustered by) userid and within each bucket the data is sorted in increasing order of viewTime. 
		The sorting property allows internal operators to take advantage of the better-known data structure while evaluating queries, also increasing efficiency. 
		MAP KEYS and COLLECTION ITEMS keywords can be used if any of the columns are lists or maps.
		The CLUSTERED BY and SORTED BY creation commands do not affect how data is inserted into a table – only how it is read. 
		This means that users must be careful to insert data correctly by specifying the number of reducers to be equal to the number of buckets, and using CLUSTER BY and SORT BY commands in their query.but,
		@ Version 0.x and 1.x only:The command set hive.enforce.bucketing = true; allows the correct number of reducers and the cluster by column to be automatically selected based on the table. 
		Otherwise, you would need to set the number of reducers to be the same as the number of buckets as in set mapred.reduce.tasks = 256; and have a CLUSTER BY ... clause in the select.

	2）查询
		referto；
			https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Sampling
		select ... from ...table_sample;
		table_sample;: TABLESAMPLE (BUCKET x OUT OF y [ON colname])
@@@The TABLESAMPLE clause allows the users to write queries for samples of the data instead of the whole table. 
		The TABLESAMPLE clause can be added to any table in the FROM clause.
		Note:非桶表也可以使用这个表达式，语法不出错，但是必须加上ON colname，而桶表可以不用加，
		In the following example the 3rd bucket out of the 32 buckets of the table source. 's' is the table alias.
				SELECT * FROM source TABLESAMPLE(BUCKET 3 OUT OF 32 ON rand()) s;
@@ Input pruning: Typically, TABLESAMPLE will scan the entire table and fetch the sample. But, that is not very efficient. Instead, the table can be created with a CLUSTERED BY clause which indicates the set of columns on which the table is hash-partitioned/clustered on. If the columns specified in the TABLESAMPLE clause match the columns in the CLUSTERED BY clause, TABLESAMPLE scans only the required hash-partitions of the table.
		Example:
			So in the above example, if table 'source' was created with 'CLUSTERED BY id INTO 32 BUCKETS'
				TABLESAMPLE(BUCKET 3 OUT OF 16 ON id)
			would pick out the 3rd and 19th clusters as each bucket would be composed of (32/16)=2 clusters.
			On the other hand the tablesample clause
				TABLESAMPLE(BUCKET 3 OUT OF 64 ON id)
			would pick out half of the 3rd cluster as each bucket would be composed of (32/64)=1/2 of a cluster.
17.Skewed Tables
 Skewed Join Optimization：
 		https://cwiki.apache.org/confluence/display/Hive/Skewed+Join+Optimization
 List Bucketing:
 		https://cwiki.apache.org/confluence/display/Hive/ListBucketing
@@@This feature can be used to improve performance for tables where one or more columns have skewed values. 
@@@By specifying the values that appear very often (heavy skew) Hive will split those out into separate files (or directories in case of list bucketing) automatically and take this fact into account during queries so that it can skip or include the whole file (or directory in case of list bucketing) if possible.
e.g.
	hive> create temporary table demo_skew(id string, name string) skewed by (name) on ('allen','kobe') stored as directories;
	hive> insert into table demo_skew values ("01","allen"), ("02","allen"), ("03","allen"), ("04","allen"), ("05","kobe"), ("06","kobe"), ("07","kobe"), ("08","wade"), ("09","thomas"), ("10","james"), ("11","jordan");
	hive> dfs -ls /tmp/hive/jiyuan/8a310dec-7463-42ad-af6e-1be8fb54615d/_tmp_space.db/ba46276d-a6ea-4d92-adf7-6add1a1dab67;
	Found 3 items
	drwx------   - jiyuan supergroup          0 2017-07-27 16:27 /tmp/hive/jiyuan/8a310dec-7463-42ad-af6e-1be8fb54615d/_tmp_space.db/ba46276d-a6ea-4d92-adf7-6add1a1dab67/HIVE_DEFAULT_LIST_BUCKETING_DIR_NAME
	drwx------   - jiyuan supergroup          0 2017-07-27 16:27 /tmp/hive/jiyuan/8a310dec-7463-42ad-af6e-1be8fb54615d/_tmp_space.db/ba46276d-a6ea-4d92-adf7-6add1a1dab67/name=allen
	drwx------   - jiyuan supergroup          0 2017-07-27 16:27 /tmp/hive/jiyuan/8a310dec-7463-42ad-af6e-1be8fb54615d/_tmp_space.db/ba46276d-a6ea-4d92-adf7-6add1a1dab67/name=kobe
	hive> dfs -ls  /tmp/hive/jiyuan/8a310dec-7463-42ad-af6e-1be8fb54615d/_tmp_space.db/ba46276d-a6ea-4d92-adf7-6add1a1dab67/name=allen;
	Found 1 items
	-rwx------   1 jiyuan supergroup         36 2017-07-27 16:27 /tmp/hive/jiyuan/8a310dec-7463-42ad-af6e-1be8fb54615d/_tmp_space.db/ba46276d-a6ea-4d92-adf7-6add1a1dab67/name=allen/000000_0
	hive> dfs -text /tmp/hive/jiyuan/8a310dec-7463-42ad-af6e-1be8fb54615d/_tmp_space.db/ba46276d-a6ea-4d92-adf7-6add1a1dab67/name=allen/000000_0;
	01allen
	02allen
	03allen
	04allen
e.g.2
	And here is an example of a table with two skewed columns.
	Example:
	CREATE TABLE list_bucket_multiple (col1 STRING, col2 int, col3 STRING)
		SKEWED BY (col1, col2) ON (('s1',1), ('s3',3), ('s13',13), ('s78',78)) [STORED AS DIRECTORIES];
		
18.Temporary Tables
	@@@A table that has been created as a temporary table will only be visible to the current session. Data will be stored in the user's scratch directory, and deleted at the end of the session.
	note:If a temporary table is created with a database/table name of a permanent table which already exists in the database, then within that session any references to that table will resolve to the temporary table, rather than to the permanent table. The user will not be able to access the original table within that session without either dropping the temporary table, or renaming it to a non-conflicting name.
	limitations:
			Partition columns are not supported.
			No support for creation of indexes.
	Starting in Hive 1.1.0 the storage policy for temporary tables can be set to memory, ssd, or default with the hive.exec.temporary.table.storage configuration parameter.
			hive.exec.temporary.table.storage
					Default Value: default
					Added In: Hive 1.1.0 with HIVE-7313
			Expects one of [memory, ssd, default].
			Define the storage policy for temporary tables. Choices between memory, ssd and default.
19.Constraints
	Status:ing...
		Version information
		As of Hive 2.1.0 (HIVE-13290).
		Hive includes support for non-validated primary and foreign key constraints. Some SQL tools generate more efficient queries when constraints are present. Since these constraints are not validated, an upstream system needs to ensure data integrity before it is loaded into Hive.
		Example:
		create table pk(id1 integer, id2 integer,
			primary key(id1, id2) disable novalidate);
		create table fk(id1 integer, id2 integer,
			constraint c1 foreign key(id1, id2) references pk(id2, id1) disable novalidate);
20.Drop table
		DROP TABLE [IF EXISTS] table_name [PURGE];     -- (Note: PURGE available in Hive 0.14.0 and later)
	DROP TABLE removes metadata and data for this table. 
	@@The data is actually moved to the .Trash/Current directory if Trash is configured (and PURGE is not specified). The metadata is completely lost.
	@@When dropping an EXTERNAL table, data in the table will NOT be deleted from the file system.
	@@ RECOVER TABLE:Users who mistakenly DROP TABLEs may  be able to recover their lost data by recreating a table with the same schema, recreating any necessary partitions, and then moving the data back into place manually using Hadoop. This solution is subject to change over time or across installations as it relies on the underlying implementation; users are strongly encouraged not to drop tables capriciously.
	If PURGE is specified, the table data does not go to the .Trash/Current directory and so cannot be retrieved in the event of a mistaken DROP. The purge option can also be specified with the table property auto.purge (see TBLPROPERTIES above).
	In Hive 0.7.0 or later, DROP returns an error if the table doesn't exist, unless IF EXISTS is specified or the configuration variable hive.exec.drop.ignorenonexistent is set to true.
21.Truncate Table
	TRUNCATE TABLE table_name [PARTITION partition_spec];
	partition_spec:
 	 : (partition_column = partition_col_value, partition_column = partition_col_value, ...)
	 The rows will be trashed if the filesystem Trash is enabled, otherwise they are deleted (as of Hive 2.2.0 with HIVE-14626). 
	 @Currently the target table should be native/managed table or an exception will be thrown. 
	 Starting with HIVE 2.3.0 (HIVE-15880) if the table property "auto.purge" (see TBLPROPERTIES above) is set to "true" the data of the table is not moved to Trash when a TRUNCATE TABLE command is issued against it and cannot be retrieved in the event of a mistaken TRUNCATE. This is applicable only for managed tables (see managed tables). 
	 This behavior can be turned off if the "auto.purge" property is unset or set to false for a managed table.
22.Alter table:Rename Table
	ALTER TABLE table_name RENAME TO new_table_name;
	As of version 0.6, a rename on a managed table moves its HDFS location. 
	@@ Rename has been changed as of version 2.2.0 (HIVE-14909) so that a managed table's HDFS location is moved only if the table is created without a LOCATION clause and under its database directory.
	For external Rename just change name, but can't change hdfs.
	e.g.
		hive> desc formatted demo_bucket_addpartiion;
		OK
		...                  
		Location:               hdfs://internal0:8020/user/hive/warehouse/s_yhb_yhbpt.db/demo_bucket_addpartiion         
		Table Type:             MANAGED_TABLE            
		...          
		hive> alter table demo_bucket_addpartiion rename to demo_bucket_addpart;
		OK
		Time taken: 0.264 seconds
		hive> desc formatted demo_bucket_addpart;
		OK
		...                                                    
		Location:               hdfs://internal0:8020/user/hive/warehouse/s_yhb_yhbpt.db/demo_bucket_addpart     
		Table Type:             MANAGED_TABLE            
		...              
23.Alter table:Alter Table Storage Properties
	ALTER TABLE table_name CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name, ...)]
		INTO num_buckets BUCKETS;
	These statements change the table's physical storage properties.
	@@ NOTE: These commands will only modify Hive's metadata, and will NOT reorganize or reformat existing data. Users should make sure the actual data layout conforms with the metadata definition.
24.Alter table:Alter Table Skewed
	ALTER TABLE table_name SKEWED BY (col_name1, col_name2, ...)
		ON ([(col_name1_value, col_name2_value, ...) [, (col_name1_value, col_name2_value), ...]
		[STORED AS DIRECTORIES];
	The STORED AS DIRECTORIES option determines whether a skewed table uses the list bucketing feature, which creates subdirectories for skewed values.
	Alter Table Not Skewed
	ALTER TABLE table_name NOT SKEWED;
	The NOT SKEWED option makes the table non-skewed and turns off the list bucketing feature (since a list-bucketing table is always skewed). This affects partitions created after the ALTER statement, but has no effect on partitions created before the ALTER statement.
	Alter Table Not Stored as Directories
	ALTER TABLE table_name NOT STORED AS DIRECTORIES;
	This turns off the list bucketing feature, although the table remains skewed.
25.Alter table:Exchange Partition
	Version information
	As of Hive 0.12 (HIVE-4095). Multiple partitions supported in Hive versions 1.2.2, 1.3.0, and 2.0.0+.
	-- Move partition from table_name_1 to table_name_2
	ALTER TABLE table_name_2 EXCHANGE PARTITION (partition_spec) WITH TABLE table_name_1;
	-- multiple partitions
	ALTER TABLE table_name_2 EXCHANGE PARTITION (partition_spec, partition_spec2, ...) WITH TABLE table_name_1;
	@ This statement lets you move the data in a partition from a table to another table that has the same schema and does not already have that partition.
26.Alter table:Alter Table/Partition Protections
	ALTER TABLE table_name [PARTITION partition_spec] ENABLE|DISABLE NO_DROP [CASCADE];
	ALTER TABLE table_name [PARTITION partition_spec] ENABLE|DISABLE OFFLINE;
	This functionality was removed in Hive 2.0.0. This functionality is replaced by using one of the several security options available with Hive (see SQL Standard Based Hive Authorization).
	@ Protection on data can be set at either the table or partition level. Enabling NO_DROP prevents a table from being dropped. 
	Enabling OFFLINE prevents the data in a table or partition from being queried, but the metadata can still be accessed.
	If any partition in a table has NO_DROP enabled, the table cannot be dropped either. 
	Conversely, if a table has NO_DROP enabled then partitions may be dropped, but with NO_DROP CASCADE partitions cannot be dropped either unless the drop partition command specifies IGNORE PROTECTION.
27.Alter Tabl:Alter Table/Partition Compact
		ALTER TABLE table_name [PARTITION (partition_key = 'partition_value' [, ...])]
			COMPACT 'compaction_type'[AND WAIT]
			[WITH OVERWRITE TBLPROPERTIES ("property"="value" [, ...])];
	The compaction_type can be MAJOR or MINOR. See the Basic Design section in Hive Transactions for more information.
28.Alter Tabl:Alter Table/Partition Concatenate
		ALTER TABLE table_name [PARTITION (partition_key = 'partition_value' [, ...])] CONCATENATE;
	@ If the table or partition contains many small RCFiles or ORC files, then the above command will merge them into larger files. 
	In case of RCFile the merge happens at block level whereas for ORC files the merge happens at stripe level thereby avoiding the overhead of decompressing and decoding the data.

28.Alter Tabl:Add/Replace Columns
		ALTER TABLE table_name 
			[PARTITION partition_spec]                 
			ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)
			[CASCADE|RESTRICT]      
	ADD COLUMNS lets you add new columns to the end of the existing columns but before the partition columns.
	REPLACE COLUMNS removes all existing columns and adds the new set of columns. This can be done only for tables with a native SerDe (DynamicSerDe, MetadataTypedColumnsetSerDe, LazySimpleSerDe and ColumnarSerDe). Refer to Hive SerDe for more information. REPLACE COLUMNS can also be used to drop columns. For example, "ALTER TABLE test_change REPLACE COLUMNS (a int, b int);" will remove column 'c' from test_change's schema.
	ALTER TABLE ADD|REPLACE COLUMNS with CASCADE command changes the columns of a table's metadata, and cascades the same change to all the partition metadata. RESTRICT is the default, limiting column changes only to table metadata.
@@@ ALTER TABLE ADD or REPLACE COLUMNS CASCADE will override the table partition's column metadata regardless of the table or partition's protection mode. Use with discretion.
	The column change command will only modify Hive's metadata, and will not modify data. Users should make sure the actual data layout of the table/partition conforms with the metadata definition.


Problem:
1. listbucketing
2.
